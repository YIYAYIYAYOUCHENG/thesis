\chapter{Background\label{chap:background}}

% COMMENT: I went very fast on this. I think the second part (the one in
% which you describe the Linux scheduler) is pretty much ok, only
% English should be checked, but this can be done later on. You need to
% work a little bit on the first part (CBS). As said later, if you feel
% you do not have time, I can help you with some cut&paste from one of
% my papers (after all it is just background work, but it needs to be
% explained for completeness.

\section{The Constant Bandwidth Server theory\label{sec:CBS}}
%
% TODO: I think you should cite Abeni's paper here. Also, you need to
% be more precise about this algorithm. You can cut&paste from a
% previous thesis (Juri's one) and then slightly re-elaborate the
% words. Don't worry about copying: Juri itself has copied from a
% previous student!
% 

%%A Constant Bandwidth Server(CBS) is characterised by a budget $c_s$ and
%%an pair $(Q_s, T_s)$, where $Q_s$ is the maximum budget and $T_s$
%%is the period of the server. 
%
% TODO: you should separate static parameters (Qs and Ts) from dynamic
% variables (cs), because the first are used to define the server, and
% the seconds are concerned with the internal working of the
% algorithm. In this case, c_s goes together with d_s.
%
%%$U_s = Q_s/T_s$ is called the server bandwidth (or utilisation).  Such
%%a server can be utilised to serve a set of tasks, which can be tasks
%%with soft, hard or non real-time guarantee requirements.  
The original CBS algorithm~\cite{AbeniB98} defines rules to reserve 
bandwidth on a single processor, and every server can manage a single 
task. The CBS algorithm was later extended to multi-processor global 
scheduling~\cite{baruah2002implementing}, and to hierarchical scheduling
~\cite{lipari2001hierarchical,journals/jec/LipariB05,Lip05-comp} (where
multiple tasks can coexist in the same server).

%
% TODO: you have to specify what does it mean hard CBS. I think you can just 
% copy and paste the rules of the CBS from somewhere.
%
%%In our work, we use a hard version of CBS.
%%
%%For a specific server $S$, at any instant, a fixed deadline $d_{s,k}$
%%is associated with the server. A CBS is said to be active at time $t$
%%if there are pending tasks and $c_s$ is not 0; otherwise it is called
%%idle.  At any time, among all active servers, the one with earliest
%%deadline is chosen. Then a served task of this server is picked to
%%execute. CBS does not restrict the rule to pick up a particular
%%task. For example, first in first out (FIFO), rate monotonic
%%scheduling and any user defined rule can be used.  As the picked task
%%executes, the server budget $c_s$ is decreased by the same
%%amount. When budget $c_s$ reaches 0, the server goes into a recharging
%%state. At each deadline point, the $c_s$ will be recharged to $Q_s$
%%and a new server deadline will be generated as $d_{s, k+1} = d_{s,k} +
%%T_k$. Initially, $c_s = Q_s$ and $d_{s, 0} = 0$. When a task arrives
%%at time $t$ and the server is idle, if $c_s \ge (d_{s,k} - t)U_s$, the
%%server updates its deadline as $d_{s, k+1} = t + T_s$ and $c_s$ is
%%recharged to maximum value $Q_s$.
%%
%%Given a set of servers $\{S_0, S_1, ... , S_n\}$, if
%%\[
%%	\sum_{i=0}^n U_i \le 1
%%\]
%%then, every $T_i$ time units, a server $S_i$ can obtain $Q_s$ time
%%units to serve its tasks. In other words, $U_i$ is the bandwidth a
%%server $S_i$ reserves from a cpu.
%%
A Constnat bandwidth server can be used to provide temporal isolation
for a tasks or a set of tasks. In the terminology of CBS theory, the 
waking up or creation of a served task is also called the arrival of a 
request for the server. The following is the classic CBS rules, 
focusing on single processor.
\begin{itemize}
\item A Constant Bandwidth Server (CBS) is characterized by an ordered pair
($Q_{s}$, $T_{s}$) where $Q_{s}$ is the maximum budget and $T_{s}$ is the
period of the server. The ratio $U_{s} = Q_{s}/T_{s}$ is denoted as the
server bandwidth. 
\item A CBS server manages two internal variables that define its state:
$c_{s}$ (initialized as $C_{s}$) is the current budget at time $t$ 
and $d_{s}$ is the current deadline assigned by the 
server to a request (zero-initialized). Requests served by different 
servers are scheduled with earliest deadline first. The $c_{s}$ will
decrease with the same value as the time a served task runs. 
\item A CBS is said to be active at time $t$ if there are pending 
requests. If a new request arrives while the server is still active,
then it is queued in a server queue or it can preempt the current 
request and the current request will be queued; this is not part of 
CBS rules and can be managed with an arbitrary discipline, 
for example FIFO. 
\item When a new request arrives at instant $t$ and the server is idle, 
there are two cases. If $c_{s} \ge (d_{s} - t)U_{s}$, then the server 
generates a new deadline ($d_{s} = d_{s} + T_{s}$) and $c_{s}$ is 
recharged to the maximum value $Q_{s}$. Otherwise, the request is 
served with the current deadline and budget value.
\item When a request is completed, the server picks the next (if it exists)
pending request from the internal queue and schedule it with the current
budget value and deadline.
\item When a budget is exhausted ($c_{s} = 0$), it is recharged at the
maximum value ($c_{s} = Q_{s}$) and the current deadline is postponed by
one period ($d_{s} = d_{s} + T_{s}$).
\end{itemize}
In our work, we use a hard version of CBS (HCBS). The HCBS rules differ 
in the situation when a server's budget is exhausted, where the budget is 
not recharged immediately as the soft resource reservation:
\begin{itemize}
\item When a budget is exhausted ($c_{s} = 0$), the server and the request
it serves are suspended until the current deadline ($d_{s}$), when the 
budget is recharged to maximum value ($c_{s} = Q_{s}$) and the deadline 
is updated by one period ($d_{s} = d_{s} + T_{s}$).
\item When a request arrives and the server is suspended, the request is
put in the server's internal queue.
\end{itemize}
By this hard variant of CBS, a server reserves exactly $Q_{s}$ units
of time every $T{s}$ time units for its requests given the condition
that the sum of all servers' utilization on a CPU is not greater than 
1.

A complete description of the CBS and of all its variant, using a
state machine formalism is available in
~\cite{DBLP:journals/rts/MancinaFLHGT09}.

%
% TODO: if you need help because you are late, I can copy and paste a
% description of the CBS from one of my papers.
%

\section{The Linux Scheduler\label{sec:LinuxSched}}

A scheduler is responsible for distributing CPU cycles to tasks in the
system according to some scheduling algorithm. In Linux, tasks refer
to a process or a thread and correspond to the data structure
\texttt{struct task\_struct}. The emphasis in this section is to
clarify the relationships and connections among different scheduling
components. % TODO: commented, this comment is not useful IMHO. As for
            % how each scheduling algorithm in Linux is
% implemented, it's neither the interest of this section or oxc
% framework.
To understand the Linux scheduling architecture is the
first step to explore the oxc framework. For details about how linux
schedulers work, people can read corresponding chapters in~\cite{Wolf}
~\cite{R.Love}.

\subsection{Scheduling classes\label{sec:LinuxSched_classes}}

Linux scheduling system adapts a modular design, and the basic
building block is a scheduling class, which is an instance of
\texttt{struct sched\_class}\footnote{Defined in
  include/linux/sched.h}. Scheduling algorithms are implemented as
scheduling classes and a scheduling class is a scheduler component (or
simply called a scheduler). The set of all schedulers compose the
generic scheduler in Linux.  The \texttt{struct sched\_class} defines
a set of interfaces that a scheduler module must implement. Each
scheduler fulfils details behind the interface and carries out its
specific scheduling behaviour.

There are three scheduling classes in mainline Linux kernel:
rt\_sched\_class, cfs\_sched\_class and idle\_sched\_class, defined in
rt.c, fair.c, and idle.c, respectively, in directory
kernel/sched. Each scheduling class is responsible for scheduling a
type of tasks. Tasks scheduled with \texttt{cfs\_sched\_class} are
called \emph{normal tasks}, and tasks scheduled by
\texttt{rt\_sched\_class} are called \emph{rt tasks}.
\texttt{idle\_sched\_class} deals with special idle tasks which do
nothing and occupy the CPU when no RT or normal tasks need a CPU.

Now, it's time to see the semantics of scheduling operations for a
scheduler. The following listing contains the main field of structure
sched\_class.
\begin{lstlisting}[language=C, 
		caption={\texttt{Scheduling operations for a scheduler}},
		label={lst:sched_class}]
struct sched_class {
	const struct sched_class *next;
	void (*enqueue_task) (struct rq *rq, struct task_struct *p, int flags);
	void (*dequeue_task) (struct rq *rq, struct task_struct *p, int flags);
	void (*check_preempt_curr) (struct rq *rq, struct task_struct *p, int flags);
	struct task_struct * (*pick_next_task) (struct rq *rq);
	void (*put_prev_task) (struct rq *rq, struct task_struct *p);
        void (*set_curr_task) (struct rq *rq);
	void (*task_tick) (struct rq *rq, struct task_struct *p, int queued);
	...
};
\end{lstlisting}
\begin{itemize} 
\item \texttt{next:}
	Scheduling classes are linked in a chain, as shown 
	in~\vref{fig:sched_classes}.  Whenever a task is needed,
	the scheduler from the beginning to the end of the chain 
	is checked and corresponding scheduling methods are called
	until a task is found. So, schedulers in front have higher 
	priority to execute their tasks. 
\item \texttt{enqueue\_task:}
	Called when a task enters a runnable state. The task is then 
	enqueued into a runqueue, which is an instance of \texttt{struct rq}.
\item \texttt{dequeue\_task:}
	When a task is no longer runnable, this function is called to move
	corresponding task from a runqueue.
\item \texttt{check\_preempt\_curr:}
	This function checks if a task that entered the runnable state 
	should preempt the currently running task.
\item \texttt{pick\_next\_task:}
	This function chooses the task to run next. The newly picked up
	one can be the one currently occupting the CPU; in this case,
	no context switches are needed.
\item \texttt{put\_prev\_task:}
	This is the last scheduling activity for a task before it gives
	up the executing opportunity on a CPU. In fact, it can happen
	that after this operation, the same task still occupies the 
	CPU, as it is picked up again through \texttt{pick\_next\_task}.
\item \texttt{set\_curr\_task:}
	This function is called when a task changes its scheduling class
	or changes its task group.
\item \texttt{task\_tick:}
	This function is the most frequently called scheduling function. 
	It is a good point to update the scheduling information, and 
	it might lead to task switch.
\end{itemize} 
\begin{figure}[htbp]
        \centering
        \includegraphics[width=\textwidth]{images/sched_classes}
        \caption{Scheduling classes in Linux}
        \label{fig:sched_classes}
\end{figure}
The basic scheduling unit in Linux is the \emph{scheduling entity},
which represents both tasks and task groups. There are two kinds of
scheduling entities \footnote{Both are defined in
  include/linux/sched.h}: CFS (scheduling) entities and RT
(scheduling) entities.  They are separately defined by \texttt{struct
  sched\_entity} and \texttt{struct sched\_rt\_entity}.  When we say a
task is enqueued in a runqueue, more precisely, it is the task's (CFS
or RT) scheduling entity that is enqueued.
\begin{lstlisting}[language=C, 
			caption={\texttt{A task embeds scheduling entities}},
			label={task_struct}]
struct task_struct {
	...
	struct sched_entity se;
	struct sched_rt_entity rt;
	...
};
\end{lstlisting}
Both CFS and RT entities are embedded in \texttt{struct task\_struct}. 
For any task, its status can switch between a CFS task and a RT task
through the system call \texttt{sched\_setscheduler}.

When \texttt{CONFIG\_FAIR\_GROUP\_SCHED} is set, CFS task grouping is
enabled. And \texttt{CONFIG\_RT\_GROUP\_SCHEED} is the kernel
configuration for RT task group scheduling. A task group can contains
both RT tasks and normal tasks, as shown in listing
~\vref{lst:task_group}. For each CPU, a task group uses a RT entity and a
CFS entity to represent its RT tasks and normal tasks on a CPU.  Each 
type of tasks inside a task group is scheduled independently by its own
scheduling class.
\begin{lstlisting}[language=C,
		caption={\texttt{A task group contains 
			both RT tasks and CFS tasks}},
			label={lst:task_group}]		

struct task_group {
#ifdef CONFIG_FAIR_GROUP_SCHED
	/* sched_entity of this group on each cpu */
	struct sched_entity **se;
	...
#endif
#ifdef CONFIG_RT_GROUP_SCHED
	/* sched_rt_entity of this group on each cpu */
	struct sched_entity **rt_se;
	...
#endif
	...
};
\end{lstlisting}

\subsection{Runqueue centered scheduling\label{LinuxSched_rq}}

Every hook in \texttt{struct sched\_class} deals with the data
structure \texttt{struct rq}\footnote{Defined in kernel/sched/sched.h},
which is called runqueue in Linux.  We say that Linux scheduling is
runqueue centered. In Linux, the \texttt{struct rq} is a per CPU data
structure; each cpu is associated with a dedicated runqueue. Despite 
its name, \texttt{struct rq} is not a queue. The \texttt{struct rq} 
contains a large amount of information. Its partial contents that are 
necessary for understanding the remaining of the thesis are listed below.
\begin{lstlisting}[language=C,
			caption={\texttt{The runqueue structure}},
			label={lst:runqueue}]
struct rq {
	...
	unsigned long nr_running;
	struct cfs_rq cfs;
	struct rt_rq rt;
	struct task_struct *curr, *idle;
	u64 clock;
	u64 clock_task;
#ifdef CONFIG_SMP
	int cpu;
#endif
	...
};
\end{lstlisting}
\begin{itemize}
\item \texttt{nr\_running} specifies the number of runnable tasks 
	having been enqueued in the runqueue.
\item \texttt{cfs and rt} are two specific runqueues for 
	\texttt{cfs\_sched\_class} and \texttt{rt\_sched\_class} respectively. 
	In order to handle specific type of tasks, different schedulers define 
	new type of runqueue data structures. 
	When we say a task is enqueued into a runqueue, it is finally into
	its corresponding specific runqueue.Each task group has one CFS 
	runqueue and RT runqueue per CPU to enqueue the tasks and sub task
	groups it contains in that CPU. 
	Listing~\vref{lst:task_group_ex} adds this new information to the
	knowledge just introduced for a task group, as in 
	listing~\vref{lst:task_group}. The default task group in the system points
	their CFS runqueue and RT runqueue to fields contained in the
	per CPU runqueue directly. 
\item \texttt{curr} points to the task currently running in this runqueue.
\item \texttt{idle} points to a special idle task. This is the task occupying
		the CPU  when no other tasks are runnable.
\item \texttt{clock and clock\_task} are time information kept by the runqueue.
	They updated by \texttt{update\_rq\_clock} method and some scheduling
	operation can rely them as time source.
\item \texttt{cpu} tells the CPU of this runqueue is devoted to.
\end{itemize}
\begin{lstlisting}[language=C,
caption={\texttt{Specific runqueue information within a task group}},
			label={lst:task_group_ex}]		

struct task_group {
#ifdef CONFIG_FAIR_GROUP_SCHED
	/* sched_entity of this group on each cpu */
	struct sched_entity **se;
	/* runqueue "owned" by this group on each cpu */
	struct cfs_rq **cfs_rq;
	...
#endif
#ifdef CONFIG_RT_GROUP_SCHED
	/* sched_rt_entity of this group on each cpu */
	struct sched_entity **rt_se;
	struct rt_rq **rt_rq;
	...
#endif
	...
};
\end{lstlisting}

\subsection{Completely Fair scheduler\label{sec:LinuxSched_cfs}}

The Completely Fair Scheduler (CFS) is implemented in
\texttt{fair\_sched\_class}.  Most tasks inside Linux are scheduled by
completely fair scheduling class and are normal tasks, which can be
further divided into three sub types given scheduling policies
(\texttt{SCHED\_NORMAL}, \texttt{SCHED\_BATCH} and
\texttt{SCHED\_IDLE\footnote{This SCHED\_IDLE policy is not related to
    idle\_sched\_class which aims to handle a special idle task.}}).

CFS tries to distribute CPU cycles fairly to tasks and task groups
according to their \emph{weight}. A specific runqueue structure
\texttt{struct cfs\_rq} is provided to deal with normal tasks.  Recall
that an instance of such cfs runqueue is embedded in the per-CPU
runqueue and each task group holds a pointer to cfs runqueue on each
CPU to store CFS tasks belonging to it.  A little more details on CFS
runqueue and CFS scheduling entity follow.
%The scheduling entity handled by CFS scheduling class is 
%\texttt{struct sched\_entity}. Here instead of studying the details of
%CFS, we are going to see how different scheduling components
\begin{lstlisting}[language=C,
		caption={\texttt{The CFS runqueue}},
		label={cfsrunqueue}]
struct cfs_rq {
        unsigned long nr_running;
        struct rb_root tasks_timeline;
#ifdef CONFIG_FAIR_GROUP_SCHED
        struct rq *rq;  
	struct task_group *tg;
#endif
	...
};
\end{lstlisting}
\begin{itemize}
\item \texttt{nr\_running} is the number of CFS tasks(entities) in this CFS 
	runqueue.
\item \texttt{tasks\_timeline} is the root of the red-black tree 
	\cite{rbtree} where 
	all CFS entities enququed into this CFS runqueue is stored. 
	This article will not go into details of the red-black tree
	mechanism, people only need to know it is an efficient way 
	to sort and access data elements.
\item \texttt{rq} is the per CPU runqueue that the task group \texttt{tg} 
	is finally enqueued.
\item \texttt{tg} is the task group that owns this CFS runqueue.
\end{itemize}
\begin{lstlisting}[language=C,
			caption={\texttt{The CFS scheduling entity}},
			label={sched_entity}]
struct sched_entity {
	...
	struct cfs_rq *cfs_rq;
#ifdef CONFIG_FAIR_GROUP_SCHED
	struct cfs_rq *my_q;
#endif
	...
}; 
\end{lstlisting}
\begin{itemize}
\item \texttt{cfs\_rq} is where this entity is to be queued.
		
\item \texttt{my\_rq} is the CFS runqueue owned by this entity(group).
	Remember that a scheduling entity can also represent a task group.
\end{itemize}
Now there is enough information to show how different scheduling components
(\texttt{sched\_entity}, \texttt{task\_struct}, \texttt{task\_group}
and \texttt{struct cfs\_rq}) are related in completely fair scheduler.

In this case that CFS task group scheduling is enabled. The CFS
scheduling scheme is shown in figure\ref{fig:cfs_scheme_tg}.  This is
not a complete scheme: 

\begin{enumerate}
\item Under a task group there could be sub groups, which behave as
  the task in the figure 
\item In the system, there is a top group, which includes all tasks in
  the system by default; tasks in this group are enqueued in the CFS
  runqueue embedded in the per CPU runqueue directly.
\end{enumerate}
\begin{figure}[htbp]
        \centering
        \includegraphics[width=\textwidth]{images/cfs_scheduling_scheme_tg}
        \caption{CFS scheduling when CFS group scheduling is enabled.}
        \label{fig:cfs_scheme_tg}
\end{figure}

If CFS task group scheduling is not enabled, a task is directed to its
per CPU runqueue by a \emph{task\_rq} marco. \emph{task\_rq} also
works for RT scheduling when RT task group scheduling is not enabled.
In fact, this \texttt{task\_rq} can be used even in case RT and CFS
task group scheduling are enabled. It just that when such task group
schedling are set, normally the information in each element in the
scheduling route is more important than simply returning a runqueue.
%\ref{fig:cfs_scheme_no_tg}.
\begin{figure}[htbp]
        \centering
        \includegraphics[height=0.1\textheight,width=0.5\textwidth]{images/scheduling_scheme_no_tg}
        \caption{Scheduling scheme without group scheduling}
        \label{fig:cfs_scheme_no_tg}
\end{figure}

We call the scheme in Figure \ref{fig:cfs_scheme_tg} and
\ref{fig:cfs_scheme_no_tg} \emph{scheduling routes} in CFS scheduling.
The route source is a task and the destination is a runqueue.  The
feature of a scheduling route is that if one component in the route is
known, then other scheduling components in the direction towards the
destination can be tracked.  The concept of scheduling route is first
invented in our work.  Later you will see the theory behind oxc
framework explores scheduling routes in Linux extensivly. We believe a
new concept is deserved in formalizing the work for oxc framework.

\subsection{Real time scheduler\label{sec:LinuxSched_rt}}

Tasks with POSIX real time policies \texttt{SCHED\_FIFO} and \texttt{SCHED\_RR}
are scheduled by the real time scheduling class \texttt{rt\_sched\_class} and
are called RT tasks. Given figure\ref{fig:sched_classes}, RT tasks are always
schedueld over normal tasks. 

\texttt{SCHED\_FIFO} implements a simple first-in, first-out scheduling 
algorithm. A running \texttt{SCHED\_FIFO} task can only be preempted by a 
higher priority RT task. \texttt{SCHED\_RR} is \texttt{SCHED\_FIFO} with 
timeslices --- it is a round robin algrithm. When a \texttt{SCHED\_RR}
task exhausts its timeslice, another \texttt{SCHED\_RR} task of the same
priprity is picked to run a timeslice, and so on. In either case, a RT task
cannot be preempted by a lower priority task.

The RT scheduling class provides with a sub runqueue structure 
\texttt{struct rt\_rq} to deal with RT tasks.
\begin{lstlisting}[language=C,
		caption={\texttt{The RT runqueue}},
		label={rtrunqueue}]
struct rt_rq {
	struct rt_prio_array active;
        unsigned long rt_nr_running;
#ifdef CONFIG_RT_GROUP_SCHED
        struct rq *rq;
        struct task_group *tg;
#endif
	...
};

struct rt_prio_array {
	DECLARE_BITMAP(bitmap, MAX_RT_PRIO+1); 
	struct list_head queue[MAX_RT_PRIO];
};
\end{lstlisting}
All RT tasks with the same priority, let's say $prio$, are kept in a linked 
list headed by $active.queue[prio]$. If there is a task in the list, the 
corresponding bit in $active.bitmap$ is set. All other fields have the same
meaning as in CFS runqueue. Compare with the CFS scheduling entity, the 
following \texttt{struct sched\_rt\_entity} is self explanatory enough. 
\begin{lstlisting}[language=C,
		caption={\texttt{The RT scheduling entity}},
		label={rt_entity}]
struct sched_rt_entity {
	...
	struct rt_rq *rt_rq;
#ifdef CONFIG_RT_GROUP_SCHED
	struct rt_rq *my_q;
#endif
	...
}; 
\end{lstlisting}

%The connections among \texttt{struct sched\_rt\_entity} and other scheduling
%components are similar to the \text{struct sched\_entity} case.
When \texttt{CONFIG\_RT\_GROUP\_SCHED} is set, figure\ref{fig:rt_scheme_tg} 
shows the scheduling route for RT scheduling. If RT task group scheduling is 
not enabled, still \emph{task\_rq} marco will be used.
\begin{figure}[htbp]
        \centering
        \includegraphics[width=\textwidth]{images/rt_scheduling_scheme_tg}
        \caption{RT scheduling when RT group scheduling is enabled.}
        \label{fig:rt_scheme_tg}
\end{figure}

\section{Related work\label{sec:RelatedWork}}
\subsection{RT throttling\label{sec:RelatedWork_RT}}
Enabling \texttt{CONFIG\_RT\_GROUP\_SCHED} lets users explicitly allocate
CPU bandiwidth to RT tasks in task groups. It uses the \emph{control group}
(cgroup) virtual file system. Each cgroup associates a set of tasks with
a set of resources, called \emph{subsystems}. For example \emph{cpuset} 
subsystem is responsible for assigning a set of CPUs and Memory Nodes to
tasks in a cgroup. Such tasks and resources can be further distributed in 
sub cgroups. Each cgroup is represented by a directory in the cgroup file 
system and a hierarchy of cgroups maps to a hierarchy of directories. In 
the directory, each mounted subsystem provides a list of files that are used 
as interfaces to control the allocation of a resource.
Through mounting the \emph{cpu} subsystem, two interfaces $cpu.rt\_period\_us$ 
and $cpu.rt\_runtime\_us$ are used to control the CPU bandwidth for RT 
tasks in each cgroup. That is, the total execution time of RT tasks in a cgroup 
on each CPU in time length $rt\_period\_us$ cannot exceed $rt\_runtime\_us$. 
If this constraint is met, RT tasks would not be choosen to run on that CPU 
until a new period; we call such tasks be throttled.

No matter \texttt{CONFIG\_RT\_GROUP\_SCHED} is set or not, in order to avoid RT 
tasks forever occupy thc CPU, there is a system wide setting that constraints
rt tasks' execution through the /proc virtual file system :

	$/proc/sys/kernel/sched\_rt\_period\_us$ 

	$/proc/sys/kernel/sched\_rt\_runtime\_us$ 
\\This applies to all RT tasks in a system.

\subsection{CFS bandwidth control\label{RelatedWork_CFS}}
Basically, CFS bandwidth control is the same technique as RT throttling
applying on normal tasks. It is a \texttt{CONFIG\_FAIR\_GROUP\_SCHED} 
extension which allows the specification of the maximum CPU bandwidth
available to normal tasks  in a cgroup or cgroup hierarchy.
The bandwidth allowed to a cgroup is specified using a 
quota(\texttt{cpu.cfs\_quota\_us}) and a period(\texttt{cpu.cfs\_period\_us}).
By specifying this, normal tasks in a cgroup will be limited to 
\texttt{cfs\_quota\_us} units of CPU time within the period of 
\texttt{cfs\_period\_us}. Recall that in RT throttling \ref{sec:RelatedWork_RT},
the reserved bandwidth through cgroup interfaces are applied in each CPU
individually.
\subsection{AQuoSA\label{sec:AQuoSA}}
The Adaptive Quality of Service Architecture composes two parts: 
a resource reservation scheduler an a feedback-based
control mechanism. The scheduler uses CBS rules to rserve CPU bandwidth for
a task, which is a RT task with SCHED\_RR policy in its Linux implementation.
Given the error between the reserved computation and the amount of CPU cycles
really consumed, the feedback controller adapts CBS reservation paramters to
provide quality of service CPU allocation in the system.
The control mechanism depends on CBS performance, not the scheduling details.
That is, such a control mechanism can be applied to general CBS based 
scheduling. AQuoSA lacks considerations on multi-processor platform.
  
\subsection{Schedule-deadline patch}
The schedule-deadline patch for Linux kernel is being developed to extend
current mainline Linux with a deadline-based scheduling method. 
In schedule-deadline, a new scheduling class (scheduler) is implemented and 
has highest priority among all scheduling classes. Tasks scheduled by this
scheduling class are called sched tasks. A sched task is assigned deadlines
according to CBS rules and scheduled in ''earliest deadline first (EDF)'' way.
\subsection{IRMOS real-time framework}
The rague name IRMOS comes from the European project ''Interactive Real-time
Multimedia Applications on Service Oriented Infrastructures''. 
The IRMOS 
framework replace RT throttling mechanism in mainline Linux with real time
CPU reservation(still CBS), and reuses the existing interfaces. So, users 
configure the cgroup interface as what we saw in RT 
throttling(\ref{sec:RelatedWork_RT}), the difference is that this time the CPU 
bandwidth is allocated in a guaranteed way. Also, new cgroup interfaces are 
added to assist reserved CPU power distribution in the cgroup hierarchy.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
