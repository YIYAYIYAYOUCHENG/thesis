\chapter{Experimental Results\label{chap:exp}}
The overhead introduced by oxc framework composes two parts:
\begin{itemize}
\item The time required to execute the code of framework functions.
\item The context switches introduced by the oxc framework.
\end{itemize}

Current oxc framework implementation is still a prototype one. Some kernel 
features are not considered under the framework yet. For example, the 
\texttt{priority inheritance}, which is important for the kernel's real time
performance and will influence number of context switches. 
However, the execution time of oxc function codes is fixed and can be measured.
As for the context switches caused by importng CBS based scheduling in the
kernel, there is previous work .... This may help readers understand what 
happens under the oxc framework. In the rest of this chapter, our experiment
will concentrate on measuring execution time of oxc functions.

\section{Ftrace in Linux kernel}
Ftrace is an internal tracer designed to help out developers of systems to
find out what is going on inside the kernel. The name ftrace comes from
''function tracer'', which is its original purpose and the reason it is 
used here. Now there are various kinds of tracers incorporated in Ftrace.
You can use it to trace context switces, hong long interrupts are disabled,
and so on.

Ftrace uses \emph{debugfs} file system to hold control files as well as
file to display output. 
Typically, ftrace is mounted at \texttt{/sys/kernel/debug}.
\begin{lstlisting}
	#mount -t debugfs nodev /sys/kernel/debug
\end{lstlisting}
After this command, a firectory \texttt{/sys/kernel/debug/tracing} will 
be created containing interfaces to configure ftrace and display results.
\begin{lstlisting}
	#cd /sys/kernel/debug/tracing
\end{lstlisting}
The following commands will be assumed to be called under \texttt{tracing}
directory.
There are several kinds of tracers available in ftrace, simply cat the
\texttt{available\_tracers} file in the \texttt{tracing} dorectory.
\begin{lstlisting}
	#cat available_tracers
	blk function_graph mmiotrace wakeup_rt wakeup function sched_switch nop
\end{lstlisting}
The \texttt{function} is function tracer. It uses the \texttt{-pg} option
of \texttt{gcc} to have every function in the kernel call a special function
\texttt{mcount()} for tracing all kernel functions and measure execution time 
of them.  This is what we need. To enable the function tracer, just \emph{echo} \texttt{function} into the \texttt{current\_tracer}
file.
\begin{lstlisting}
	#echo function > current_tracer
\end{lstlisting}
The trace can be started and stopped through configuring \texttt{tracing\_on}
file. Echo 0 into this file to disable the tracer or 1 to enable it. Cat the
file will displat whether the tracer is enabled or not.

The output of the trace in held in file \texttt{trace} in a human readable
format. The ftrace will by default trace all functions in the kernel. In
most cases, people only care about particular functions. To dynamically
configure which function to trace, the \texttt{CONFIG\_DYNAMIC\_FTRACE}
kernel option should be set in compilation time  to enable dynamic ftrace. 
Actually, \texttt{CONFIG\_DYNAMIC\_FTRACE} is highly recommanded and defaultly
set because of its performance enhancement. To filter which function to trace
or not, two files are used, one for enabling and one for disabling the 
tracing of specific functions. They are \texttt{set\_ftrace\_filter} and 
\texttt{set\_ftrace\_notrace}. A list of available functions that you can add
to these files is listed in \texttt{available\_filter\_functions}.

\section{Experiment set up}

The hardware and software used in the experiment is shown in 
table \ref{tab:exp_setup}.
\begin{table}[hbp]
  \centering
  \begin{tabular}{ll}\hline
	\emph{Hardware platform}\hspace{4cm}		& 	\\
	Processor			& Intel(R) Core(TM) Duo E8500	 \\
	Frequency			& 3.16GHz\\
					&	\\	
	\emph{Software platform}\hspace{4cm}		& 	\\
	Linux distribution		& Ubuntu 11.10\\
	Compiler version		& gcc 4.6.1\\
	Kernel version			& 3.4.0-rc+ \\\hline
  \end{tabular}
  \caption{Hardware-Software platform}
  \label{tab:exp_setup}
\end{table}

In a Linux system, even if the oxc patch is applied in the kernel, when there is
no reservation enabled, the system performs as a plain Linux system. The possible
overheads in this case include the code execution time in function 
\texttt{is\_oxc\_task} and the oxc related initialization when a scheduling group
is created; both are negligible.

In the following experiments, we compare the oxc way to control cpu bandwidth 
with two non real-time CPU power management methods inside the kernel: 
rt throtttling and cfs bandwidth control.
%In the experiment, different number of hyper oxc numbers in a system is
%considered: 1, 2, and 4 ox containers. Each oxc contains 2 dummy tasks, which are 
%assigned to different CPUs and run 100 micro seconds every 1 milli second.
%A dummy task is simply a forever while loop. 
%
%As for kernel options concern with scheduling, 
%\texttt{CONFIG\_FAIR\_GROUP\_SCHED} is set and \texttt{CONFIG\_RT\_GROUP\_SCHED} 
%and \texttt{CONFIG\_CFS\_BANDWIDTH} are not set. During tests for cfs tasks,
%only tasks in the top cgroup in the system and an ox container are tested.
%
\section{tbench}
Tbench is a filesystem benchmark that generates load patterns similar to those
of the commercial Netbench benchmark, but without requiring a lab of Windows
load generators to run.




\section{The oxc control \emph{vs.} cfs bandwidth control}
\section{The oxc control \emph{vs.} rt throttling}
The oxc framework and rt throttling mechanism can manage CPU bandwidth for 
rt tasks in real-time and non real-time respectively. In this section, the 
overhead brought by our oxc control is compared with the result when rt 
throttling is used.
e
The load used is Fixed Time Quanta \cite{ftq} benchmark, executed at rt 
priority. FTQ measures the amount of work done in a fixed time quantum
periodically. 
\subsection{To enqueue a task and dequeue a task}

